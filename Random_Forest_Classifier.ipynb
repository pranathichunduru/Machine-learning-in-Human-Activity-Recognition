{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>0.272946</td>\n",
       "      <td>-0.026206</td>\n",
       "      <td>-0.097924</td>\n",
       "      <td>-0.991364</td>\n",
       "      <td>-0.943502</td>\n",
       "      <td>-0.982904</td>\n",
       "      <td>-0.992612</td>\n",
       "      <td>-0.940185</td>\n",
       "      <td>-0.983258</td>\n",
       "      <td>-0.926985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774672</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>-0.000998</td>\n",
       "      <td>0.701185</td>\n",
       "      <td>-0.759881</td>\n",
       "      <td>-0.812518</td>\n",
       "      <td>0.225955</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>15</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>0.271550</td>\n",
       "      <td>-0.010033</td>\n",
       "      <td>-0.104589</td>\n",
       "      <td>-0.015317</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>-0.279122</td>\n",
       "      <td>-0.033019</td>\n",
       "      <td>-0.063419</td>\n",
       "      <td>-0.324204</td>\n",
       "      <td>-0.008328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138324</td>\n",
       "      <td>0.314252</td>\n",
       "      <td>0.233292</td>\n",
       "      <td>0.884944</td>\n",
       "      <td>0.323620</td>\n",
       "      <td>-0.767534</td>\n",
       "      <td>0.247209</td>\n",
       "      <td>-0.043840</td>\n",
       "      <td>22</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>0.276674</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>-0.106707</td>\n",
       "      <td>-0.996087</td>\n",
       "      <td>-0.994709</td>\n",
       "      <td>-0.984658</td>\n",
       "      <td>-0.996586</td>\n",
       "      <td>-0.994575</td>\n",
       "      <td>-0.983022</td>\n",
       "      <td>-0.941940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468672</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>-0.072564</td>\n",
       "      <td>-0.041340</td>\n",
       "      <td>0.521934</td>\n",
       "      <td>-0.675011</td>\n",
       "      <td>0.195767</td>\n",
       "      <td>-0.192074</td>\n",
       "      <td>16</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>0.291316</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.072461</td>\n",
       "      <td>-0.336609</td>\n",
       "      <td>-0.279162</td>\n",
       "      <td>-0.303323</td>\n",
       "      <td>-0.381421</td>\n",
       "      <td>-0.253026</td>\n",
       "      <td>-0.337381</td>\n",
       "      <td>0.074430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698254</td>\n",
       "      <td>-0.044663</td>\n",
       "      <td>-0.551806</td>\n",
       "      <td>-0.680774</td>\n",
       "      <td>0.161405</td>\n",
       "      <td>-0.857202</td>\n",
       "      <td>0.192929</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>27</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>0.276414</td>\n",
       "      <td>-0.018260</td>\n",
       "      <td>-0.106016</td>\n",
       "      <td>-0.991494</td>\n",
       "      <td>-0.983043</td>\n",
       "      <td>-0.994530</td>\n",
       "      <td>-0.992532</td>\n",
       "      <td>-0.987565</td>\n",
       "      <td>-0.994456</td>\n",
       "      <td>-0.936281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887039</td>\n",
       "      <td>0.037702</td>\n",
       "      <td>-0.602658</td>\n",
       "      <td>0.040593</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>0.591757</td>\n",
       "      <td>-0.576933</td>\n",
       "      <td>-0.427187</td>\n",
       "      <td>19</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "2726           0.272946          -0.026206          -0.097924   \n",
       "4490           0.271550          -0.010033          -0.104589   \n",
       "3110           0.276674          -0.017101          -0.106707   \n",
       "5995           0.291316          -0.001065          -0.072461   \n",
       "3686           0.276414          -0.018260          -0.106016   \n",
       "\n",
       "      tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "2726         -0.991364         -0.943502         -0.982904         -0.992612   \n",
       "4490         -0.015317          0.090323         -0.279122         -0.033019   \n",
       "3110         -0.996087         -0.994709         -0.984658         -0.996586   \n",
       "5995         -0.336609         -0.279162         -0.303323         -0.381421   \n",
       "3686         -0.991494         -0.983043         -0.994530         -0.992532   \n",
       "\n",
       "      tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X    ...     \\\n",
       "2726         -0.940185         -0.983258         -0.926985    ...      \n",
       "4490         -0.063419         -0.324204         -0.008328    ...      \n",
       "3110         -0.994575         -0.983022         -0.941940    ...      \n",
       "5995         -0.253026         -0.337381          0.074430    ...      \n",
       "3686         -0.987565         -0.994456         -0.936281    ...      \n",
       "\n",
       "      fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "2726                        -0.774672                     0.001787   \n",
       "4490                         0.138324                     0.314252   \n",
       "3110                        -0.468672                     0.039139   \n",
       "5995                        -0.698254                    -0.044663   \n",
       "3686                        -0.887039                     0.037702   \n",
       "\n",
       "      angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "2726                             -0.000998                          0.701185   \n",
       "4490                              0.233292                          0.884944   \n",
       "3110                             -0.072564                         -0.041340   \n",
       "5995                             -0.551806                         -0.680774   \n",
       "3686                             -0.602658                          0.040593   \n",
       "\n",
       "      angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "2726                             -0.759881             -0.812518   \n",
       "4490                              0.323620             -0.767534   \n",
       "3110                              0.521934             -0.675011   \n",
       "5995                              0.161405             -0.857202   \n",
       "3686                             -0.489430              0.591757   \n",
       "\n",
       "      angle(Y,gravityMean)  angle(Z,gravityMean)  subject  Activity  \n",
       "2726              0.225955             -0.004362       15  STANDING  \n",
       "4490              0.247209             -0.043840       22   WALKING  \n",
       "3110              0.195767             -0.192074       16   SITTING  \n",
       "5995              0.192929              0.046716       27   WALKING  \n",
       "3686             -0.576933             -0.427187       19    LAYING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load train and test datasets and shuffle the data \n",
    "train = shuffle(pd.read_csv(\"../Human_Activity_Recognition/human-activity-recognition-with-smartphones/train.csv\"))\n",
    "test = shuffle(pd.read_csv(\"../Human_Activity_Recognition/human-activity-recognition-with-smartphones/test.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing sample in training set: False\n",
      "Any missing sample in test set: False \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0               count\n",
       "Activity                 \n",
       "LAYING               1407\n",
       "SITTING              1286\n",
       "STANDING             1374\n",
       "WALKING              1226\n",
       "WALKING_DOWNSTAIRS    986\n",
       "WALKING_UPSTAIRS     1073"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of training and test data to check for missing values\n",
    "print(\"Any missing sample in training set:\",train.isnull().values.any())\n",
    "print(\"Any missing sample in test set:\",test.isnull().values.any(), \"\\n\")\n",
    "\n",
    "#Frequency distribution of classes\"\n",
    "train_outcome = pd.crosstab(index=train[\"Activity\"],  # Make a crosstab\n",
    "                              columns=\"count\")      # Name the count column\n",
    "\n",
    "train_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Train set (7352, 561)\n",
      "Dimension of Test set (2947, 561) \n",
      "\n",
      "Number of numeric features: 561\n"
     ]
    }
   ],
   "source": [
    "# Seperating Predictors and Outcome values from train and test sets\n",
    "X_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\n",
    "Y_train = train.Activity.values.astype(object)\n",
    "X_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\n",
    "Y_test = test.Activity.values.astype(object)\n",
    "\n",
    "# Dimension of Train and Test set \n",
    "print(\"Dimension of Train set\",X_train.shape)\n",
    "print(\"Dimension of Test set\",X_test.shape,\"\\n\")\n",
    "\n",
    "# Transforming non numerical labels into numerical labels\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# encoding train labels \n",
    "encoder.fit(Y_train)\n",
    "Y_train_label = encoder.transform(Y_train)\n",
    "\n",
    "# encoding test labels \n",
    "encoder.fit(Y_test)\n",
    "Y_test_label = encoder.transform(Y_test)\n",
    "\n",
    "#Total Number of Continous and Categorical features in the training set\n",
    "num_cols = X_train._get_numeric_data().columns\n",
    "print(\"Number of numeric features:\",num_cols.size)\n",
    "#list(set(X_train.columns) - set(num_cols))\n",
    "\n",
    "\n",
    "names_of_predictors = list(X_train.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tGravityAcc-arCoeff()-Z,2       tGravityAcc-arCoeff()-Z,1        -0.995297\n",
       "tGravityAcc-arCoeff()-Z,1       tGravityAcc-arCoeff()-Z,2        -0.995297\n",
       "angle(Z,gravityMean)            tGravityAcc-mean()-Z             -0.995070\n",
       "tGravityAcc-mean()-Z            angle(Z,gravityMean)             -0.995070\n",
       "tGravityAcc-arCoeff()-Z,2       tGravityAcc-arCoeff()-Z,3        -0.994684\n",
       "tGravityAcc-arCoeff()-Z,3       tGravityAcc-arCoeff()-Z,2        -0.994684\n",
       "tGravityAcc-arCoeff()-Z,4       tGravityAcc-arCoeff()-Z,3        -0.994256\n",
       "tGravityAcc-arCoeff()-Z,3       tGravityAcc-arCoeff()-Z,4        -0.994256\n",
       "angle(Y,gravityMean)            tGravityAcc-mean()-Y             -0.993502\n",
       "tGravityAcc-mean()-Y            angle(Y,gravityMean)             -0.993502\n",
       "angle(Z,gravityMean)            tGravityAcc-max()-Z              -0.992869\n",
       "tGravityAcc-max()-Z             angle(Z,gravityMean)             -0.992869\n",
       "tGravityAcc-arCoeff()-Y,1       tGravityAcc-arCoeff()-Y,2        -0.991898\n",
       "tGravityAcc-arCoeff()-Y,2       tGravityAcc-arCoeff()-Y,1        -0.991898\n",
       "tGravityAcc-min()-Z             angle(Z,gravityMean)             -0.990991\n",
       "angle(Z,gravityMean)            tGravityAcc-min()-Z              -0.990991\n",
       "angle(Y,gravityMean)            tGravityAcc-max()-Y              -0.990841\n",
       "tGravityAcc-max()-Y             angle(Y,gravityMean)             -0.990841\n",
       "tGravityAcc-min()-Y             angle(Y,gravityMean)             -0.990047\n",
       "angle(Y,gravityMean)            tGravityAcc-min()-Y              -0.990047\n",
       "tGravityAcc-arCoeff()-X,4       tGravityAcc-arCoeff()-X,3        -0.989856\n",
       "tGravityAcc-arCoeff()-X,3       tGravityAcc-arCoeff()-X,4        -0.989856\n",
       "tGravityAcc-arCoeff()-X,2       tGravityAcc-arCoeff()-X,1        -0.989752\n",
       "tGravityAcc-arCoeff()-X,1       tGravityAcc-arCoeff()-X,2        -0.989752\n",
       "tGravityAcc-arCoeff()-Y,3       tGravityAcc-arCoeff()-Y,2        -0.989747\n",
       "tGravityAcc-arCoeff()-Y,2       tGravityAcc-arCoeff()-Y,3        -0.989747\n",
       "angle(X,gravityMean)            tGravityAcc-energy()-X           -0.989607\n",
       "tGravityAcc-energy()-X          angle(X,gravityMean)             -0.989607\n",
       "tGravityAcc-arCoeff()-X,3       tGravityAcc-arCoeff()-X,2        -0.989342\n",
       "tGravityAcc-arCoeff()-X,2       tGravityAcc-arCoeff()-X,3        -0.989342\n",
       "                                                                    ...   \n",
       "fBodyAccJerk-std()-Z            fBodyAccJerk-std()-Z              1.000000\n",
       "fBodyAccJerk-std()-Y            fBodyAccJerk-std()-Y              1.000000\n",
       "fBodyAccJerk-std()-X            fBodyAccJerk-std()-X              1.000000\n",
       "fBodyAccJerk-mean()-Z           fBodyAccJerk-mean()-Z             1.000000\n",
       "fBodyAccJerk-mean()-Y           fBodyAccJerk-mean()-Y             1.000000\n",
       "fBodyAccJerk-mean()-X           fBodyAccJerk-mean()-X             1.000000\n",
       "fBodyAcc-bandsEnergy()-25,48.2  fBodyAcc-bandsEnergy()-25,48.2    1.000000\n",
       "fBodyAcc-bandsEnergy()-1,24.2   fBodyAcc-bandsEnergy()-1,24.2     1.000000\n",
       "fBodyAcc-bandsEnergy()-49,64.2  fBodyAcc-bandsEnergy()-49,64.2    1.000000\n",
       "fBodyAccJerk-min()-X            fBodyAccJerk-min()-X              1.000000\n",
       "fBodyAccJerk-kurtosis()-X       fBodyAccJerk-kurtosis()-X         1.000000\n",
       "fBodyAccJerk-min()-Y            fBodyAccJerk-min()-Y              1.000000\n",
       "fBodyAccJerk-sma()              fBodyAccJerk-sma()                1.000000\n",
       "fBodyAccJerk-meanFreq()-Z       fBodyAccJerk-meanFreq()-Z         1.000000\n",
       "fBodyAccJerk-meanFreq()-Y       fBodyAccJerk-meanFreq()-Y         1.000000\n",
       "fBodyAccJerk-meanFreq()-X       fBodyAccJerk-meanFreq()-X         1.000000\n",
       "fBodyAccJerk-maxInds-Z          fBodyAccJerk-maxInds-Z            1.000000\n",
       "fBodyAccJerk-maxInds-Y          fBodyAccJerk-maxInds-Y            1.000000\n",
       "fBodyAccJerk-maxInds-X          fBodyAccJerk-maxInds-X            1.000000\n",
       "fBodyAccJerk-entropy()-Z        fBodyAccJerk-entropy()-Z          1.000000\n",
       "fBodyAccJerk-entropy()-Y        fBodyAccJerk-entropy()-Y          1.000000\n",
       "fBodyAccJerk-entropy()-X        fBodyAccJerk-entropy()-X          1.000000\n",
       "fBodyAccJerk-iqr()-Z            fBodyAccJerk-iqr()-Z              1.000000\n",
       "fBodyAccJerk-iqr()-Y            fBodyAccJerk-iqr()-Y              1.000000\n",
       "fBodyAccJerk-iqr()-X            fBodyAccJerk-iqr()-X              1.000000\n",
       "fBodyAccJerk-energy()-Z         fBodyAccJerk-energy()-Z           1.000000\n",
       "fBodyAccJerk-energy()-Y         fBodyAccJerk-energy()-Y           1.000000\n",
       "fBodyAccJerk-energy()-X         fBodyAccJerk-energy()-X           1.000000\n",
       "fBodyAccJerk-min()-Z            fBodyAccJerk-min()-Z              1.000000\n",
       "angle(Z,gravityMean)            angle(Z,gravityMean)              1.000000\n",
       "Length: 314721, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing correlation matrix of predictors set to determine highly correlated variables \n",
    "train_corr = X_train.corr()\n",
    "\n",
    "### Plotting Correlation Matrix \n",
    "# Generate a mask for the upper triangle\n",
    "#mask = np.zeros_like(train_corr, dtype=np.bool)\n",
    "#mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "#f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "#cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "#sns.heatmap(train_corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "#            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "\n",
    "# List of Highly correlated features in the dataset\n",
    "corr_pred = train_corr.unstack()\n",
    "high_corr_pred= corr_pred.sort_values(kind=\"quicksort\")\n",
    "high_corr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Train and Test feature set \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'n_estimators': [100, 200, 300,500]\n",
    "}\n",
    "# Create a based model\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf_classifier, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "#rf_classifier.fit(X_train_scaled, Y_train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=100 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=100 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=100 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=200 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=200 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=200 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=300 .............\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=300 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=100, total=   9.5s\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=300 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=100, total=   9.7s\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=500 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=100, total=   9.8s\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=500 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=200, total=  19.4s\n",
      "[CV] bootstrap=True, max_features=auto, n_estimators=500 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=200, total=  19.3s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=100 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=200, total=  19.4s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=100 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=300, total=  29.5s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=100 .............\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=100, total=  10.3s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=300, total=  29.5s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=100, total=  10.2s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=300, total=  31.4s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=300 .............\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=100, total=  11.3s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=300 .............\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=200, total=  22.6s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=300 .............\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=200, total=  22.6s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=200, total=  22.8s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=500, total=  53.9s\n",
      "[CV] bootstrap=True, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=500, total=  54.0s\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=300, total=  32.9s\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=300, total=  32.8s\n",
      "[CV]  bootstrap=True, max_features=auto, n_estimators=500, total=  55.0s\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=300, total=  29.0s\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=500, total=  41.9s\n",
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=500, total=  41.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:  1.6min remaining:    8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=True, max_features=sqrt, n_estimators=500, total=  37.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_features': ['auto', 'sqrt'], 'n_estimators': [100, 200, 300, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, Y_train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Performance evaluation of the trained model consists of following steps:\n",
    "\n",
    " -> Predicting the acticity class of the test data using test feature set (X_test). \n",
    "\n",
    " -> Evaluating the performance of the classifier using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537   0   0   0   0   0]\n",
      " [  0 444  47   0   0   0]\n",
      " [  0  45 487   0   0   0]\n",
      " [  0   0   0 482   8   6]\n",
      " [  0   0   0  23 356  41]\n",
      " [  0   0   0  32   7 432]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       537\n",
      "          1       0.91      0.90      0.91       491\n",
      "          2       0.91      0.92      0.91       532\n",
      "          3       0.90      0.97      0.93       496\n",
      "          4       0.96      0.85      0.90       420\n",
      "          5       0.90      0.92      0.91       471\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2947\n",
      "\n",
      "Training set score for RF: 1.000000\n",
      "Testing  set score for RF: 0.929080\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "best_model = grid_search.best_estimator_\n",
    "Y_pred_label = best_model.predict(X_test_scaled)\n",
    "Y_pred = list(encoder.inverse_transform(Y_pred_label))\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\n",
    "print(confusion_matrix(Y_test_label,Y_pred_label))\n",
    "print(\"\\n\")\n",
    "print(classification_report(Y_test_label,Y_pred_label))\n",
    "\n",
    "print(\"Training set score for RF: %f\" % best_model.score(X_train_scaled , Y_train_label))\n",
    "print(\"Testing  set score for RF: %f\" % best_model.score(X_test_scaled  , Y_test_label ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
